{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40233ba2",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45674b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce213a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_openai(OpenAI())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8652af2c",
   "metadata": {},
   "source": [
    "#### Random text longer than 2000 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3981ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The morning light filtered through the dusty venetian blinds of the old observatory on Creston Hill, casting long amber stripes across the oak floorboards. Dr. Mara Vellincourt had been awake since three in the morning, which was not unusual for her. What was unusual was the reading on her spectral analyzer — a machine she had built herself over the course of eleven years, soldering each component by hand in the small workshop behind her cottage. The reading suggested something she had long theorized but never expected to actually observe: a gravitational lens of extraordinary precision, positioned almost exactly forty-two light-years from Earth, bending light from a distant quasar into a perfect ring.\n",
    "She removed her glasses and rubbed her eyes. The numbers didn't change.\n",
    "Outside, the village of Creston was beginning its slow, reluctant awakening. The baker on Tollhouse Lane was sliding trays of sourdough into his stone oven. The postwoman, a stout woman named Brigitte who had held the route for twenty-three years, was cycling uphill with her canvas bag. A pair of crows argued loudly over a discarded sandwich wrapper near the churchyard wall. None of them had any idea that forty-two light-years away, something was bending the fabric of spacetime in a way that shouldn't — by any current model of physics — be naturally occurring.\n",
    "Mara picked up her phone and called her colleague, Professor Anand Krishnamurthy, in Bangalore. It was eight-thirty in the morning there, and he answered on the second ring.\n",
    "\"You're not going to believe what I'm looking at,\" she said.\n",
    "\"Try me,\" he said, the faint sound of a ceiling fan audible in the background.\n",
    "She read him the numbers. There was a long silence.\n",
    "\"That's not a natural lens,\" he said finally.\n",
    "\"No,\" she agreed. \"It's not.\"\n",
    "\n",
    "The history of astronomy is, in many ways, a history of humility. Each time humanity has believed itself to be at the center of something — the solar system, the galaxy, the universe — the evidence has gently, and sometimes brutally, corrected that assumption. Copernicus displaced Earth from the center of the cosmos. Hubble demonstrated that the Milky Way was just one of countless galaxies, drifting in an ocean of space so vast that the mind could not meaningfully contain it. And yet, despite these repeated lessons in cosmic insignificance, there has always persisted a stubborn hope: that somewhere out there, something is paying attention.\n",
    "The search for extraterrestrial intelligence has taken many forms over the decades. Radio telescopes have swept the sky for structured signals. Mathematicians have debated what a truly universal language might look like — whether prime numbers or geometric ratios would serve as the grammar of a first contact. Philosophers have argued about whether contact, if it came, would represent salvation or catastrophe. And engineers, practical and undeterred, have built ever more sensitive instruments to peer into the dark.\n",
    "Mara Vellincourt belonged to a quieter tradition. She was not looking for messages. She was looking for artifacts — physical structures, on a cosmic scale, that could not be explained by natural processes. It was a field that many of her colleagues considered eccentric at best, delusional at worst. Tenure committees were not known to reward the search for alien megastructures. But Mara had a small inheritance from her grandmother, a tenured position she had secured through more conventional research, and a stubbornness that her ex-husband had once described, not entirely without affection, as \"geological.\"\n",
    "\n",
    "The lens, as she came to call it in her notebooks, did not behave like any known natural phenomenon. Gravitational lensing — the bending of light around massive objects — was well understood. Einstein had predicted it. Astronomers had observed it thousands of times. But natural lenses were diffuse, smeared across the sky in arcs and halos, shaped by the irregular distribution of dark matter and ordinary mass. This lens was precise. Impossibly precise. The ring it produced was clean and symmetrical, almost perfectly circular, with a resolution that implied a degree of positional stability that no known astrophysical object could maintain over the relevant timescales.\n",
    "Over the following weeks, Mara collected data obsessively. She wrote to three other observatories — one in Chile, one in Hawaii, one in the Canary Islands — requesting confirmation observations without explaining why. Two of them complied, assuming it was routine. The third, run by a famously territorial director named Professor Haklen, refused on the grounds that her request was \"insufficiently motivated by current theoretical frameworks,\" which Mara considered a form of poetry.\n",
    "The confirmations came back positive. The lens was real. It was there. And it was, by any reasonable measure, not supposed to exist.\n",
    "\n",
    "There is a particular kind of loneliness that comes with knowing something that no one else yet knows. It is not a comfortable loneliness. It sits in the chest like a held breath, pressing outward. Mara had felt it once before, years ago, when she had first suspected that the gravitational anomaly catalogued as NGC-7741-X was not a peculiar dark matter distribution but a coherent structure — a hypothesis that had taken her four years to build into a publishable argument and another two years to get past the reviewers. She had been right, in the end. The paper had attracted modest attention. A journalist at a science magazine had called it \"intriguing.\" Her mother had framed the article and hung it in the kitchen.\n",
    "This was different.\n",
    "She told Anand everything over a series of late-night calls. He was cautious, methodical, and deeply unsettled. He ran his own calculations and came to the same conclusions. They agreed not to publish yet — not until they understood more, not until they had ruled out every possible instrumental artifact or natural explanation. This was partly scientific rigor and partly, though neither of them said it directly, fear. Not fear of being wrong. Fear of being right.\n",
    "\n",
    "In the evenings, when the data was processing and there was nothing to do but wait, Mara walked along the coastal path that ran behind the observatory. The sea was grey and restless this time of year, throwing itself against the limestone cliffs with a persistence that seemed almost personal. She would stand at the edge and look out at the horizon, which was, of course, not really the edge of anything — just the limit of her perspective, a line drawn by the curvature of the Earth and the biology of her eyes.\n",
    "She thought about what it would mean. Not in the abstract, theoretical sense that she and Anand discussed in their calls, speaking carefully in the language of astrophysics and statistical significance. But in the plain, human sense. Someone — something — had placed an object of enormous mass at a precise location in space, forty-two light-years from Earth, positioned to create a perfect gravitational lens aimed at our solar system. Aimed, in fact, with extraordinary precision, at the specific region of sky visible from the northern hemisphere during the late autumn months.\n",
    "Aimed, it seemed, at Creston Hill.\n",
    "She knew this was almost certainly not literally true. The lens covered a broad enough region of sky that it could be aimed at hundreds of star systems simultaneously. The specificity was probably an illusion, a product of her proximity to the discovery and the very human tendency to place oneself at the center of things. She knew this. She reminded herself of it regularly.\n",
    "But the numbers kept being what they were.\n",
    "\n",
    "Winter came early that year. The first snow fell in October, light and apologetic, melting before it reached the pavement. Mara's heating system broke down twice. She ate too much toast and not enough vegetables, and had a recurring dream in which she was standing in an enormous library, looking for a book whose title she could not remember, while someone she couldn't see kept quietly rearranging the shelves.\n",
    "In December, she finally wrote the paper. It was forty-three pages long, densely mathematical, and written in the careful, hedged language of a scientist who knows she is standing at the edge of something she cannot see the bottom of. She sent it to Anand. He made seventeen changes and sent it back. She made nine more. They went back and forth like this for six weeks.\n",
    "In February, they submitted it to a journal. The reviewers took four months. One called it \"extraordinary and credible.\" One called it \"extraordinary and not credible.\" The third called it \"the most significant observation in the history of astronomy, if correct, and the most embarrassing, if not,\" which at least had the virtue of precision.\n",
    "It was published on a Thursday. By Friday, Mara's phone had stopped being a phone and had become a kind of controlled emergency.\n",
    "The crows were still arguing outside the churchyard wall. The baker was still making sourdough. The postwoman was still cycling uphill. The world had not changed yet, not in any way you could see from the surface. But forty-two light-years away, something enormous and deliberate was bending light toward a small blue planet, and now, at last, the small blue planet knew it.\n",
    "Whether it was a greeting, a warning, a test, or simply a marker — a cosmic cairn left by someone passing through — no one yet knew. Perhaps no one ever would. But Mara Vellincourt stood at her window on Creston Hill, watching the snow begin again, and felt the held breath in her chest slowly, carefully, begin to release.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b18a0",
   "metadata": {},
   "source": [
    "#### Completion statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbdf896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_usage_and_cost(raw_response):\n",
    "\n",
    "    input_price = 3/1000000\n",
    "    output_price = 12/1000000\n",
    "    cached_price = 0.75/1000000\n",
    "\n",
    "    input_tokens = raw_response.usage.prompt_tokens\n",
    "    output_tokens = raw_response.usage.completion_tokens\n",
    "    cached_tokens = raw_response.usage.prompt_tokens_details.cached_tokens\n",
    "    non_cached_tokens = input_tokens - cached_tokens\n",
    "\n",
    "    print(f\"Input tokens: {input_tokens}\")\n",
    "    print(f\"Output tokens: {output_tokens}\")\n",
    "    print(f\"Cached tokens: {cached_tokens}\")\n",
    "    print(f\"Non-cached tokens: {non_cached_tokens}\")\n",
    "\n",
    "    print(f\"Output cost: {output_tokens * output_price}\")\n",
    "    print(f\"Cached cost: {cached_tokens * cached_price}\")\n",
    "    print(f\"Non-cached cost: {non_cached_tokens * input_price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be94f4b",
   "metadata": {},
   "source": [
    "#### Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = f\"\"\"\n",
    "Extract names from the following text:\n",
    "\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = f\"\"\"\n",
    "Extract places from the following text:\n",
    "\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f7367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractedNames(BaseModel):\n",
    "    names: list[str]\n",
    "\n",
    "class ExtractedPlaces(BaseModel):\n",
    "    places: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1fa5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1, raw_response_1 = client.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4.1\",\n",
    "    response_model=ExtractedNames,\n",
    "    messages=[{\"role\": \"system\", \"content\": prompt_1}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2, raw_response_2 = client.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4.1\",\n",
    "    response_model=ExtractedPlaces,\n",
    "    messages=[{\"role\": \"system\", \"content\": prompt_2}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ade0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96bc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea3902c",
   "metadata": {},
   "source": [
    "#### Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b42c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3 = f\"\"\"\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "Extract names from the text between <text> and </text> tags.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8acb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_4 = f\"\"\"\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "Extract places from the text between <text> and </text> tags.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcdd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_3, raw_response_3 = client.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4.1\",\n",
    "    response_model=ExtractedNames,\n",
    "    messages=[{\"role\": \"system\", \"content\": prompt_3}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cbe7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_4, raw_response_4 = client.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4.1\",\n",
    "    response_model=ExtractedPlaces,\n",
    "    messages=[{\"role\": \"system\", \"content\": prompt_4}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28484a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0d146a",
   "metadata": {},
   "source": [
    "#### Test 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d041b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_3_1 = f\"\"\"\n",
    "Following is the text with more than 2000 tokens.\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "Extract names from the text between <text> and </text> tags.\n",
    "\"\"\"\n",
    "\n",
    "prompt_4_1 = f\"\"\"\n",
    "Following is the text with more than 2000 tokens.\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "Extract places from the text between <text> and </text> tags.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edf637",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_3_1, raw_response_3_1 = client.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4.1\",\n",
    "    response_model=ExtractedNames,\n",
    "    messages=[{\"role\": \"system\", \"content\": prompt_3_1}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7715ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_4_1, raw_response_4_1 = client.chat.completions.create_with_completion(\n",
    "    model=\"gpt-4.1\",\n",
    "    response_model=ExtractedPlaces,\n",
    "    messages=[{\"role\": \"system\", \"content\": prompt_4_1}],\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2520f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f17a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_4_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654dfd03",
   "metadata": {},
   "source": [
    "#### Test 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractionResults(BaseModel):\n",
    "    names: Optional[list[str]] = None\n",
    "    places: Optional[list[str]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e27ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_5 = f\"\"\"\n",
    "Following is the text with more than 2000 tokens.\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "Extract names from the text between <text> and </text> tags, leave places as null.\n",
    "\"\"\"\n",
    "\n",
    "prompt_6 = f\"\"\"\n",
    "Following is the text with more than 2000 tokens.\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\n",
    "Extract places from the text between <text> and </text> tags, leave names as null.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0de8b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_5, raw_response_5 = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ExtractionResults,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt_5}],\n",
    "        temperature=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_6, raw_response_6 = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ExtractionResults,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt_6}],\n",
    "        temperature=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5d2fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb07242",
   "metadata": {},
   "source": [
    "#### Test 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8d6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_7 = f\"\"\"\n",
    "Following is the text with more than 2000 tokens.\n",
    "<text>\n",
    "{text}\n",
    "</text>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fda20",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_7, raw_response_7 = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ExtractionResults,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt_7},\n",
    "        {\"role\": \"user\", \"content\": \"Extract names from the text between <text> and </text> tags, leave places as null.\"}],\n",
    "        temperature=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_8, raw_response_8 = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ExtractionResults,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt_7},\n",
    "        {\"role\": \"user\", \"content\": \"Extract places from the text between <text> and </text> tags, leave names as null.\"}],\n",
    "        temperature=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52669fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529c448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c00de4",
   "metadata": {},
   "source": [
    "#### Test 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed469fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_9, raw_response_9 = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ExtractedNames,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt_7},\n",
    "        {\"role\": \"user\", \"content\": \"Extract names from the text between <text> and </text> tags.\"}],\n",
    "        temperature=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d221e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_10, raw_response_10 = client.chat.completions.create_with_completion(\n",
    "        model=\"gpt-4.1\",\n",
    "        response_model=ExtractedPlaces,\n",
    "        messages=[{\"role\": \"system\", \"content\": prompt_7},\n",
    "        {\"role\": \"user\", \"content\": \"Extract places from the text between <text> and </text> tags.\"}],\n",
    "        temperature=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4d9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_usage_and_cost(raw_response_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398d28ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
