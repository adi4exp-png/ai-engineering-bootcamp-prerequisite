{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87264138",
   "metadata": {},
   "source": [
    "### Import Dependencies ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "653dd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastmcp import Client\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchText, FusionQuery\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage, convert_to_openai_messages\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "from utils.utils import format_ai_message\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa1307",
   "metadata": {},
   "source": [
    "### List available tools in MCP servers running on http://localhost:8001/mcp and http://localhost:8002/mcp ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4da9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"http://localhost:8001/mcp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71af94aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "async with client:\n",
    "    tools  = await client.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fabc57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='get_formatted_item_context', title=None, description='Get the top k context, each representing an inventory item for a given query.\\n\\nArgs:\\n    query: The query to get the top k context for\\n    top_k: The number of context chunks to retrieve, works best with 5 or more\\n\\nReturns:\\n    A string of the top k context chunks with IDs and average ratings prepending each chunk, each representing an inventory item for a given query.', inputSchema={'properties': {'query': {'type': 'string'}, 'top_k': {'default': 5, 'type': 'integer'}}, 'required': ['query'], 'type': 'object'}, outputSchema={'properties': {'result': {'type': 'string'}}, 'required': ['result'], 'type': 'object', 'x-fastmcp-wrap-result': True}, icons=None, annotations=None, meta={'_fastmcp': {'tags': []}}, execution=None)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13a5c539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======NAME=======\n",
      "get_formatted_item_context\n",
      "======DESCRIPTION=======\n",
      "Get the top k context, each representing an inventory item for a given query.\n",
      "\n",
      "Args:\n",
      "    query: The query to get the top k context for\n",
      "    top_k: The number of context chunks to retrieve, works best with 5 or more\n",
      "\n",
      "Returns:\n",
      "    A string of the top k context chunks with IDs and average ratings prepending each chunk, each representing an inventory item for a given query.\n",
      "======INPUT SCHEMA=======\n",
      "{'properties': {'query': {'type': 'string'}, 'top_k': {'default': 5, 'type': 'integer'}}, 'required': ['query'], 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "print(\"======NAME=======\")\n",
    "print(tools[0].name)\n",
    "print(\"======DESCRIPTION=======\")\n",
    "print(tools[0].description)\n",
    "print(\"======INPUT SCHEMA=======\")\n",
    "print(tools[0].inputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0379c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(\"http://localhost:8002/mcp\")\n",
    "\n",
    "async with client:\n",
    "    tools  = await client.list_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e978284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='get_formatted_reviews_context', title=None, description='Get the top k reviews matching a query for a list of prefiltered items.\\n\\nArgs:\\n    query: The query to get the top k reviews for\\n    item_list: The list of item IDs to prefilter for before running the query\\n    top_k: The number of reviews to retrieve, this should be at least 20 if multipple items are prefiltered\\n\\nReturns:\\n    A string of the top k context chunks with IDs prepending each chunk, each representing a review for a given inventory item for a given query.', inputSchema={'properties': {'query': {'type': 'string'}, 'item_list': {'items': {}, 'type': 'array'}, 'top_k': {'default': 15, 'type': 'integer'}}, 'required': ['query', 'item_list'], 'type': 'object'}, outputSchema={'properties': {'result': {'type': 'string'}}, 'required': ['result'], 'type': 'object', 'x-fastmcp-wrap-result': True}, icons=None, annotations=None, meta={'_fastmcp': {'tags': []}}, execution=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bab9489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======NAME=======\n",
      "get_formatted_reviews_context\n",
      "======DESCRIPTION=======\n",
      "Get the top k reviews matching a query for a list of prefiltered items.\n",
      "\n",
      "Args:\n",
      "    query: The query to get the top k reviews for\n",
      "    item_list: The list of item IDs to prefilter for before running the query\n",
      "    top_k: The number of reviews to retrieve, this should be at least 20 if multipple items are prefiltered\n",
      "\n",
      "Returns:\n",
      "    A string of the top k context chunks with IDs prepending each chunk, each representing a review for a given inventory item for a given query.\n",
      "======INPUT SCHEMA=======\n",
      "{'properties': {'query': {'type': 'string'}, 'item_list': {'items': {}, 'type': 'array'}, 'top_k': {'default': 15, 'type': 'integer'}}, 'required': ['query', 'item_list'], 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "print(\"======NAME=======\")\n",
    "print(tools[0].name)\n",
    "print(\"======DESCRIPTION=======\")\n",
    "print(tools[0].description)\n",
    "print(\"======INPUT SCHEMA=======\")\n",
    "print(tools[0].inputSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0c7334",
   "metadata": {},
   "source": [
    "### Execute a tool on one of the running MCP Servers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5f7009f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ToolError",
     "evalue": "Unknown tool: get_formatted_items_context",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mToolError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m client = Client(\u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:8001/mcp\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m client:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m client.call_tool(\u001b[33m\"\u001b[39m\u001b[33mget_formatted_items_context\u001b[39m\u001b[33m\"\u001b[39m, {\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWhat earphones can I get?\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m5\u001b[39m})\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/workspace/ai-engineering-bootcamp-prerequisite/.venv/lib/python3.12/site-packages/fastmcp/client/client.py:1430\u001b[39m, in \u001b[36mClient.call_tool\u001b[39m\u001b[34m(self, name, arguments, timeout, progress_handler, raise_on_error, meta, task, task_id, ttl)\u001b[39m\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_tool_as_task(name, arguments, task_id, ttl)\n\u001b[32m   1423\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.call_tool_mcp(\n\u001b[32m   1424\u001b[39m     name=name,\n\u001b[32m   1425\u001b[39m     arguments=arguments \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m     meta=meta,\n\u001b[32m   1429\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._parse_call_tool_result(\n\u001b[32m   1431\u001b[39m     name, result, raise_on_error=raise_on_error\n\u001b[32m   1432\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/workspace/ai-engineering-bootcamp-prerequisite/.venv/lib/python3.12/site-packages/fastmcp/client/client.py:1317\u001b[39m, in \u001b[36mClient._parse_call_tool_result\u001b[39m\u001b[34m(self, name, result, raise_on_error)\u001b[39m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.isError \u001b[38;5;129;01mand\u001b[39;00m raise_on_error:\n\u001b[32m   1316\u001b[39m     msg = cast(mcp.types.TextContent, result.content[\u001b[32m0\u001b[39m]).text\n\u001b[32m-> \u001b[39m\u001b[32m1317\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ToolError(msg)\n\u001b[32m   1318\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m result.structuredContent:\n\u001b[32m   1319\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mToolError\u001b[39m: Unknown tool: get_formatted_items_context"
     ]
    }
   ],
   "source": [
    "client = Client(\"http://localhost:8001/mcp\")\n",
    "\n",
    "async with client:\n",
    "    result = await client.call_tool(\"get_formatted_items_context\", {\"query\": \"What earphones can I get?\", \"top_k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f8524f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
